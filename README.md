# ğŸ¤– `LLM` RAG 

## ğŸŒŸ Overview 
This is a Streamlit app leveraging a RAG (Retrieval-Augmented Generation) Language Model (LLM) with FAISS to offer answers from uploaded markdown files ğŸ“‚. The app allows users to upload files, ask questions related to the content of these files, and receive relevant answers generated by the RAG LLM ğŸ“š.

## ğŸ› ï¸ System Architecture
The following diagram illustrates the flow of data through the system:

```mermaid
graph TD
    A[User Files] -->|Read & Process| B[Semantic Database Setup]
    B -->|Generate Embeddings & FAISS Index| C[Vector Store]
    C -->|Utilize OpenAI's Models| D[Semantic Search]
    E[User Query] -->|Vectorization| D
    D -->|Select Top Documents| F[Top Documents]
    F -->|Include Selected Docs in Context| G[Contextualized Documents]
    E -->|Determine Expertise using OpenAI| H[Expertise Area]
    H -->|Formulate Prompt| I[Prompt with Context]
    G --> I
    I -->|Query OpenAI LLM| J[LLM Response]
    J -->|Generate Answer| K[Answer]

    style A fill:#7f7f7f,stroke:#fff,stroke-width:2px
    style B fill:#8fa1b3,stroke:#fff,stroke-width:2px
    style C fill:#8fa1b3,stroke:#fff,stroke-width:2px
    style D fill:#8fa1b3,stroke:#fff,stroke-width:2px
    style E fill:#7f7f7f,stroke:#fff,stroke-width:2px
    style F fill:#8fa1b3,stroke:#fff,stroke-width:2px
    style G fill:#8fa1b3,stroke:#fff,stroke-width:2px
    style H fill:#8fa1b3,stroke:#fff,stroke-width:2px
    style I fill:#e07b53,stroke:#fff,stroke-width:2px
    style J fill:#e07b53,stroke:#fff,stroke-width:2px
    style K fill:#e07b53,stroke:#fff,stroke-width:2px
```

## Project Structure ğŸ—ï¸
The project structure is organized as follows, ensuring modularity and ease of maintenance:

```
LLM-RAG/
â”‚
â”œâ”€â”€ src/                        # Source code for the application
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                 
â”‚   â”‚   â”œâ”€â”€ inference.py        # ModelInferenceManager class
â”‚   â”‚   â””â”€â”€ vectorization.py    # SemanticVectorizer class
â”‚   â”‚
â”‚   â”œâ”€â”€ pipelines/              # Pipeline for processing queries
â”‚   â”‚   â””â”€â”€ query_pipeline.py   # QueryPipeline class
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                  # Utility functions and classes
â”‚   â”‚   â””â”€â”€ utils.py            # Helper functions, e.g., for loading configs
â”‚   â”‚
â”‚   â””â”€â”€ __init__.py             # Makes src a Python module
â”‚
â”œâ”€â”€ configs/                    # Configuration files
â”‚   â””â”€â”€ models_config.yml       # Model configurations
â”‚
â”œâ”€â”€ data/                       # Data used by the application
â”‚   â”œâ”€â”€ raw/                    # Raw data like markdown files
â”‚   â”œâ”€â”€ processed/              # Processed data like embeddings
â”‚   â””â”€â”€ faiss_index/            # FAISS indices
â”‚
â”œâ”€â”€ notebooks/                  # Jupyter notebooks for experiments
â”‚   â””â”€â”€ rag_llm_experiments.ipynb
â”‚
â”œâ”€â”€ secrets/                    # Secret keys and credentials
â”‚   â””â”€â”€ credentials.yml         # OpenAI API credentials
â”‚
â”œâ”€â”€ app.py                      # Main Streamlit application script
â”œâ”€â”€ requirements.txt            # Python dependencies for the project
â”œâ”€â”€ README.md                   # Project documentation
â””â”€â”€ .gitignore                  # Specifies files to ignore in git
```

## ğŸš€ Getting Started

To begin using the LLM RAG app, follow these simple steps:

1. **Clone the Repository:**
   ```
   git clone https://github.com/labrijisaad/LLM-RAG.git
   ```

2. **Create the Environment:**
   Set up your virtual environment using either venv or conda:
   ```
   # Using venv
   python -m venv env
   source env/bin/activate
   
   # Using conda
   conda create --name env_name
   conda activate env_name
   ```

3. **Install Dependencies:**
   Install the required dependencies by

 running:
   ```
   pip install -r requirements.txt
   ```

4. **Set Up OpenAI API:**
   Rename the example credentials file to `secrets/credentials.yml` and replace the placeholder key ('sk-xxx') with your actual OpenAI API key. You can obtain your API key by following the instructions provided in the [OpenAI documentation](https://platform.openai.com/docs/quickstart?context=python).
   ```
   rename secrets/credentials-example.yml secrets/credentials.yml
   ```

5. **Run the Streamlit App:**
   Launch the Streamlit app using either the provided Makefile command or directly via the Streamlit CLI:
   ```
   # Using Makefile
   make stream
   
   # Or directly
   streamlit run streamlit_app/main.py
   ```

## ğŸŒ Connect with me
<div align="center">
  <a href="https://www.linkedin.com/in/labrijisaad/">
    <img src="https://img.shields.io/badge/LinkedIn-%230077B5.svg?&style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn" style="margin-bottom: 5px;"/>
  </a>
  <a href="https://github.com/labrijisaad">
    <img src="https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white" alt="GitHub" style="margin-bottom: 5px;"/>
  </a>
</div>
